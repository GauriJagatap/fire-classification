{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import cv2 as cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as scio\n",
    "import h5py\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract data\n",
    "comb_data = h5py.File('combustion_img_13.mat','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = comb_data['train_set_x'][()]\n",
    "y_train = comb_data['train_set_y'][()]\n",
    "X_test = comb_data['test_set_x'][()]\n",
    "y_test = comb_data['test_set_y'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54000, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final = np.zeros([54000,1250])\n",
    "n=len(X_train_final[:,1])\n",
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauri/anaconda2/lib/python2.7/site-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "#Feature extraction using Histogram of Gradients\n",
    "#Training data\n",
    "for i in range(0,n):\n",
    "    temp_image = X_train[:,i]\n",
    "    \n",
    "    temp_image = np.reshape(temp_image,[250,100])\n",
    "    temp_image = temp_image.T\n",
    "    temp_fd = hog(temp_image, orientations=5, pixels_per_cell=(10, 10),\n",
    "                    cells_per_block=(1, 1))\n",
    "    \n",
    "    X_train_final[i,:] = temp_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract features of test data using Histogram of Gradients\n",
    "X_test_final = np.zeros([18000,1250])\n",
    "b=len(X_test_final[:,1])\n",
    "for i in range(0,b):\n",
    "    temp_image = X_test[:,i]\n",
    "    \n",
    "    temp_image = np.reshape(temp_image,[250,100])\n",
    "    temp_image = temp_image.T\n",
    "    temp_fd = hog(temp_image, orientations=5, pixels_per_cell=(10, 10),\n",
    "                    cells_per_block=(1, 1))\n",
    "    \n",
    "    X_test_final[i,:] = temp_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning the dictionary...\n",
      "done in 139.96s.\n"
     ]
    }
   ],
   "source": [
    "#Feature extraction using Dictionary Learning\n",
    "#Training data\n",
    "print('Learning the dictionary...')\n",
    "t0 = time()\n",
    "dico = MiniBatchDictionaryLearning(n_components=10, alpha=1, n_iter=100)\n",
    "X_train_dict = dico.fit_transform(X_train.T)\n",
    "np.shape(X_train_dict)\n",
    "dt = time() - t0\n",
    "print('done in %.2fs.' % dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Express test data in terms of (Dictionary) learned features\n",
    "X_test_dict = dico.transform(X_test.T)\n",
    "np.shape(X_test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random forest classifier for HOG features # n_features = 1250\n",
    "num_features = \"auto\" #default option \"auto\" = sqrt(n_features); \"log2\" = log2(n_features); None = n_features \n",
    "clf = RandomForestClassifier(n_estimators=2, max_features=num_features, max_depth=4, random_state=0)\n",
    "clf.fit(X_train_final, np.ravel(y_train))\n",
    "\n",
    "#Random forest classifier for dictionary features # n_features = 10\n",
    "num_features_d = \"auto\" #default option \"auto\" = sqrt(n_features); \"log2\" = log2(n_features); None = n_features \n",
    "clfd = RandomForestClassifier(n_estimators=2, max_features=num_features_d, max_depth=4, random_state=0)\n",
    "clfd.fit(X_train_dict, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest Classifier using HOG features... %.2f 0.956055555556\n"
     ]
    }
   ],
   "source": [
    "#Test classification accuracy using Random Forest Classifier for HOG features\n",
    "\n",
    "y_test_predict=clf.predict(X_test_final)\n",
    "acc = accuracy_score(y_test, y_test_predict)\n",
    "print('Accuracy of Random Forest Classifier using HOG features is...',acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest Classifier using Dictionary learned features is... 0.929333333333\n"
     ]
    }
   ],
   "source": [
    "#Test classification accuracy using Random Forest Classifier for dictionary features\n",
    "\n",
    "y_test_predictd=clfd.predict(X_test_dict)\n",
    "acc_d = accuracy_score(y_test, y_test_predictd)\n",
    "print('Accuracy of Random Forest Classifier using Dictionary learned features is...',acc_d)\n",
    "\n",
    "\n",
    "#### CODE IS COMPLETE TILL THIS POINT ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### CODE NEEDS TO BE FIXED BEYOND THIS POINT ####\n",
    "\n",
    "#KFold Cross validation\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "kf.get_n_splits(X_train_final)\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X_train_final):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train_kfold, X_test_kfold = X_train_final[train_index], X_train_final[test_index]\n",
    "    y_train_kfold, y_test_kfold = y_train[train_index], y_train[test_index]\n",
    "\n",
    "np.shape(y_train)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train_kfold, y_train_kfold)\n",
    "clf.score(X_test_kfold, y_test_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grid search\n",
    "X_train_gs, X_test_gs, y_train_gs, y_test_gs = train_test_split(\n",
    "    X_train_final, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = [{\"classifier__n_estimators\": [1, 2, 3, 4, 5], \"classifier__max_depth\": [2, 4, 6, 8, 10]}]\n",
    "scores = ['precision', 'recall']\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train_gs, y_train_gs)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test_gs, clf.predict(X_test_gs)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
